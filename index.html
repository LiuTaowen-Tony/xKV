<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="xKV: Cross-Layer SVD for KV-Cache Compression">
  <meta property="og:title" content="xKV"/>
  <meta property="og:description" content="xKV: Cross-Layer SVD for KV-Cache Compression"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/overview.jpg" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="xKV">
  <meta name="twitter:description" content="xKV: Cross-Layer SVD for KV-Cache Compression">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/image/overview.jpg">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KV Cache">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>xKV: Cross-Layer SVD for KV-Cache Compression-</title>
  <link rel="icon" type="image/x-icon" href="static/images/xKV_logo_cute.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            
            <div class="is-size-5 publication-authors">
            <h1 class="title is-2 publication-title"><img src="static/images/xKV_logo_cute.png" alt="xKV" width="50" height="50" style="display: inline; vertical-align: bottom;" />&nbsp;xKV: Cross-Layer SVD for KV-Cache Compression</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Chi-Chih Chang</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Chien-Yu Lin</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Yash Akhauri</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Wei-Cheng Lin</a><sup>3</sup>,
              </span><br>
              <span class="author-block">
                <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Kai-Chiang Wu</a><sup>3</sup>,
              </span>
              <span class="author-block">
                <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Luis Ceze</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Mohamed S. Abdelfattah </a><sup>1</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="affliation"><small><sup>1</sup>Cornell University, <sup>2</sup>University of Washington, </span><br> <sup>3</sup>National Yang Ming Chiao Tung University</span>
            </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/abdelfattah-lab/xKV.git" target="_blank"
                    class="external-link button is-normal is-rounded is-dark"
                    style="color: #fff !important;"
                    >
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2503.18893" target="_blank"
                  class="external-link button is-normal is-rounded is-dark"
                  style="color: #fff !important;"
                  >
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <!-- Title with icon -->
        <h4 class="title is-4">
          <img src="static/images/target.png" style="height: 40px; display: inline; vertical-align: middle;"/>
          &nbsp; Abstract
        </h4>
        <!-- The figure block -->
        <div class="figure" style="text-align: center;">
          <img src="static/images/teaser.png"
               alt=""
               style="max-width: 100%; height: auto;" />
        </div>
                
        <div class="level-set has-text-justified">
          <p>
            Large Language Models (LLMs) with long context windows enable powerful applications but come at the cost of high memory consumption to store the Key and Value states (KV-Cache). Recent efforts to compress KV-Cache—such as token eviction, quantization, and low-rank decomposition—have primarily focused on intra-layer redundancies that compress each layer’s KV-Cache independently. While this often yields respectable per-layer compression, these methods do not exploit potential redundancy across layers. Moreover, attempts to merge the KV-cache from multiple layers typically require expensive training or rely on assumptions of high per-token cosine similarity, which does not generally hold in practice.
          </p><br>
          <p>
            In this work, we identify that the dominant singular vectors are remarkably well-aligned across multiple layers of the KV-Cache. Leveraging this alignment, we introduce <strong>xKV</strong>, a simple post-training method that applies SVD on the KV-Cache of a group of layers. Our method consolidates the KV-Cache of multiple layers into a shared low-rank subspace, yielding a more compact KV-Cache representations.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light is-small" style="padding: 0rem 1.5rem;">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <!-- Title with icon -->
        <h4 class="title is-4">
          <img src="static/images/startup.png" style="height: 43px; display: inline; vertical-align: middle;"/>
          &nbsp;Highlights
        </h4>

         <!-- Bullet Points -->
         <div class="content" style="margin-bottom: 1rem;">
          <ul style="list-style-type: disc; margin-left: 1.5em;">
            <li><strong>Up to 8× KV-Cache reduction</strong> 
                on widely-used LLMs (e.g., Llama-3.1 and Qwen2.5) 
                while maintaining accuracy.
            </li>
            <li><strong>3× compression rate</strong> on coding tasks 
                for Multi-Head Latent Attention (MLA) models 
                (e.g., DeepSeek-Coder-V2) without performance degradation.
            </li>
          </ul>
        </div>

        <div class="figure" style="text-align: center;">
          <img src="static/images/ruler.jpg"
                 alt="Accuracy comparison"
                 style="max-width: 90%; height: auto; border-radius: 8px;" />
            <p class="subtitle has-text-centered" style="font-size: 1rem; margin-top: 0.75em;">
              Accuracy comparison of MiniCache, applying SVD on single layer’s KV-Cache
              and xKV (cross-layer SVD) on Llama-3.1-8B-Instruct (left) 
              and Qwen2.5-14B-Instruct-1M (right). Results are averaged across tasks from RULER benchmark.
            </p>
        </div>
        <br>

        <div class="figure" style="text-align: center;">
          <img src="static/images/deepseek-coder.jpg"
                 alt="DeepSeek evaluation"
                 style="max-width: 90%; height: auto; border-radius: 8px;" />
            <p class="subtitle has-text-centered" style="font-size: 1rem; margin-top: 0.75em;">
              Evaluation results of different KV-Cache methods 
              on DeepSeek-Coder-V2-Lite-Instruct model.
            </p>
            <br>
          </div>
      </div>
    </div>
  </div>
</section>





<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{chang2024palu,
  title={xKV: Cross-Layer SVD for KV-Cache Compression},
  author={Chang, Chi-Chih and Lin, Chien-Yu and Akhauri, Yash and Lin, Wei-Cheng and Wu, Kai-Chiang and Ceze, Luis and Abdelfattah, Mohamed S.},
  year={2025},
  journal={arXiv preprint arXiv:2503.18893},
  year={2025}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>. Icons created by <a href="https://www.flaticon.com">Smashicons - Flaticon</a>
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
